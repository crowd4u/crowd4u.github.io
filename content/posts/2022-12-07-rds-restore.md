---
title: "RDS上のDBのデータをローカルで同期できる環境を作った話"
date: 2022-12-01T14:54:39+09:00
draft: false
author: gild
tags: [ "NextCrowd4u", "AWS" ]
---

初めまして、融合知能デザイン研究室に仮配属中のギルドです。(留年しなければ「仮」がとれるはず。。。)\
融合知能デザイン研究室で開発しているNextCrowd4uの開発チームに最近加わったため、加入後に初めて行ったことについて書いていきたいと思います。

## NextCrowd4u(N4U)について

まだブログも創設から間もないという事で、NextCrowd4Uについてザックリ説明していこうと思います。
NextCrowd4u(以下N4U)は、「世界をより良い場所にするためのマイクロタスクを実行するための非営利プラットフォーム」として2008年ごろから稼働している[Crowd4u](https://crowd4u.org/ja/)の後継システムです。
N4U開発チームで具体的にどんなことを行ってきたかについては、[こちらの記事](../2022-11-30-intro/)をご覧ください。

## N4Uの開発現場で発生していたﾁｮｯﾄ面倒な事

さて、実際の開発ではサーバー上のコードを直接編集。。。するわけは当然なく、基本はローカルの環境で開発して、GitHubでコミットやらレビューやらしてからデプロイするわけですが、そうなると実際のサービスのデータをローカルでも扱いたいというニーズが出てきます(本番環境とデータが同期されていた方がテストが行いやすいので)。
これまでは、本番環境のデータをローカル環境(テスト環境)で使用するために、踏み台サーバーを2回通してSCPコマンドを使ってデータベースを取得する必要がありました。
ですが、正直テストのたびにこれをやるのは非常に面倒という事で、もう少し手軽に本番とローカルのデータを同期したいというニーズが生まれました。

## やったこと

やったことは非常にシンプルで、N4Uを稼働しているサーバーから、1日1回DBをダンプして踏み台サーバーに送るような環境を作成します。(図1)
そして、ローカルでリストア用のスクリプトを実行することで、踏み台サーバーにアクセスし、ダンプされたDBをダウンロードして、ローカルのデータベースにリストアするようにしました。\
(補足ですが、N4UはAWSをインフラとして使っており、DBはAmazon RDS for MySQLを使用しています。)
{{<figure src="/posts/2022-12-07/n4u-db-restore.drawio.png" width="75%" alt="図1">}}

これを実現するためにやったこととしては
- N4Uサーバー
    1. DB(RDS for MySQL)をダンプし、踏み台に送信するシェルスクリプトを作成する(dump.sh)
    2. 上記のスクリプトを定期的に実行する(cron)
- 踏み台サーバー
    1. AWSでEC2の環境を新しく作成する
    2. nginxを導入し、ベーシック認証ができるようにする
- ローカル環境 \
    以下のようなシェルスクリプトを作成する。(restore.sh)
    1. 踏み台サーバーからDBをダウンロードする
    2. ローカルのDBにリストアする

踏み台サーバーの設定に関しては、私が書くよりも分かりやすい記事がたくさんあるかと思います。\
そのため、ここからはDBのダンプスクリプトとリストアスクリプトについて書いていきます。

### N4Uサーバー：DBを定期的にダンプする
**1. DBをダンプする`dump.sh`を作成する**\
というわけで、以下のようなダンプスクリプトを作成しました。データベースの容量がある程度大きいことが想定されますのでgzipを使用して圧縮をしています。

```bash {linenos=true, linenostart=1, name="dump.sh"}
#!/bin/bash

# RDSからDBをダンプする(dump.sqlを作成)
mysqldump -h {RDSのホスト名} -P {ポート番号} -u {ユーザー名} -p{パスワード} -p {DB名} > dump.sql

# gzipに圧縮
gzip dump.sql

# scpコマンドで踏み台に送信する
scp -i {秘密鍵のパス} dump.sql.gz {踏み台のホスト名}:{踏み台のダウンロード先のパス}
```
パス等が多いという事もあり、文字だらけですが以上のようなスクリプトを作成しました。\
注意する点としては、パスワードは`-p`の後に空白を入れずに入力するという事です。空白を入れてしまうとDB名として認識されてしまいます。\
また、私の環境での話ですが、パスワードをDB名より先に入力しないと`-p {DB名}`の部分がパスワードとして認識されてしまい、ダンプできないという現象が発生しました。\
そのため、パスワードを先に記述してエラーを回避しています。

**2. `dump.sh`を定期的に実行する**\
次にこのスクリプトを定期的に実行していきます。\
AWSということで、Amazon EventBridge！と行きたいところですが、AWSを使用した開発経験が過去に皆無だったこともあり、無難にcronで定期実行することにしました。\
コマンドラインで以下をたたき、crontabを開きます。
```bash {linenos=true, linenostart=1}
crontab -e
```
次にcronのスクリプトを書いていきます。\
以下は毎日16時00分にシェルスクリプトを実行するスクリプトです。(なおEC2ではUTC時間使っているので、実際には深夜1時)
パスは適宜書き換えてください(ex. `~/tools/dump.sh`)
```bash {linenos=true, linenostart=1}
0 16 * * * sh dump.sh
```
ちなみにcronの時間指定は`{分} {時} {日} {月} {曜日}`で、指定しない項目には`*`を指定します。\
以上の設定でN4Uサーバー上で毎日DBをダンプする環境が出来上がりました！

### ローカル環境：DBを踏み台からダウンロードしてリストアする
N4UサーバーからDBをダンプして踏み台に送信できるようになったので、ローカル環境でリストアするスクリプトを書いていきます。
ちなみにダウンロードには`wget`コマンドを使用して行っていきます。
また、先述した通り踏み台サーバーはベーシック認証を設定しているため、wgetのオプションで指定し、ローカル環境としてDockerを使用しているためDockerコンテナのMySQLにリストアしていきます。
```bash {linenos=true, linenostart=1, name="restore.sh"}
#!/bin/bash

# DBをwgetでベーシック認証を挟んでダウンロードする
wget -P {ダウンロード先のパス} --http-user={ユーザー名} --http-passwd={パスワード} http://{踏み台のIPアドレス}:{ポート番号}/dump.sql.gz
# gzip化されているので解凍する
gunzip -f dump.sql.gz
# Dockerコンテナ内のSQLにリストアする
cat dump.sql | docker-compose -T {コンテナ名} mysql -u {ユーザー名} -p{パスワード} -p {DB名}
```
以上で`restore.sh`も完成しました！\
以上のスクリプトをローカル環境で実行することで(`bash restore.sh`)、ローカル環境に本番環境のデータが同期されるようになりました！

## おわりに
以上が私がN4Uの開発チームに入ってからの初めての仕事になります。
ここまで拙文にお付き合いいただきありがとうございました！